{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import matplotlib.pylab as pylab\n",
    "from pylab import plot,show\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import math\n",
    "from sklearn import cross_validation\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Limit rows disp# Limit rows displayed in notebook\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.precision', 2)\n",
    "pylab.rcParams['figure.figsize'] = 16, 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading business details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd_lasvegas = pickle.load( open('pd_lasvegas.pkl', 'rb'))\n",
    "'''\n",
    "pd_lasvegas = pd_lasvegas[np.isfinite(pd_lasvegas[u'attributes_Price Range'])]\n",
    "pd_lasvegas.rename(columns={'date_x': 'review_date'}, inplace=True)\n",
    "pd_lasvegas.rename(columns={'date_y': 'start_date'}, inplace=True)\n",
    "pd_lasvegas.rename(columns={'stars_y': 'stars'}, inplace=True)\n",
    "pd_lasvegas.reset_index(level=0, inplace=True)\n",
    "'''\n",
    "pd_old_business_vegas = pd_lasvegas[pd_lasvegas['new'] == False]\n",
    "pd_new_business_vegas = pd_lasvegas[pd_lasvegas['new'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating business vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 0, 1, -1, -1, -1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 4.9970971697914965]\n"
     ]
    }
   ],
   "source": [
    "''' Business Attributes '''\n",
    "attrs = [u'attributes_Accepts Credit Cards', \n",
    "         u'attributes_Accepts Insurance',\n",
    "         u'attributes_Ages Allowed', \n",
    "         u'attributes_Alcohol',\n",
    "         u'attributes_Ambience', \n",
    "         u'attributes_Attire', \n",
    "         u'attributes_BYOB',\n",
    "         u'attributes_BYOB/Corkage', \n",
    "         u'attributes_By Appointment Only',\n",
    "         u'attributes_Caters', \n",
    "         u'attributes_Coat Check',\n",
    "         u'attributes_Corkage', \n",
    "         u'attributes_Delivery',\n",
    "         u'attributes_Dietary Restrictions', \n",
    "         u'attributes_Dogs Allowed',\n",
    "         u'attributes_Drive-Thru', \n",
    "         u'attributes_Good For Dancing', \n",
    "         u'attributes_Good For Groups',\n",
    "         u'attributes_Good For Kids', \n",
    "         u'attributes_Hair Types Specialized In', \n",
    "         u'attributes_Happy Hour',\n",
    "         u'attributes_Has TV', \n",
    "         u'attributes_Music',\n",
    "         u'attributes_Noise Level', \n",
    "         u'attributes_Open 24 Hours',\n",
    "         u'attributes_Order at Counter', \n",
    "         u'attributes_Outdoor Seating',\n",
    "         u'attributes_Parking', \n",
    "         u'attributes_Payment Types',\n",
    "         u'attributes_Price Range', \n",
    "         u'attributes_Smoking',\n",
    "         u'attributes_Take-out', \n",
    "         u'attributes_Takes Reservations',\n",
    "         u'attributes_Waiter Service', \n",
    "         u'attributes_Wheelchair Accessible',\n",
    "         u'attributes_Wi-Fi', \n",
    "         u'categories',\n",
    "         u'hours_Friday', \n",
    "         u'hours_Monday', \n",
    "         u'hours_Saturday',\n",
    "         u'hours_Sunday', \n",
    "         u'hours_Thursday', \n",
    "         u'hours_Tuesday',\n",
    "         u'hours_Wednesday',\n",
    "         'distance'\n",
    "        ]\n",
    "\n",
    "def find_distance(o_bid, n_bid, old, new):\n",
    "    lat1=old['latitude']\n",
    "    long1=old['longitude']\n",
    "    lat2=new['latitude']\n",
    "    long2=new['longitude']\n",
    "    if lat1==lat2 and long1==long2:\n",
    "        return 0\n",
    "    # Convert latitude and longitude to \n",
    "    # spherical coordinates in radians.\n",
    "    degrees_to_radians = math.pi/180.0\n",
    "         \n",
    "    # phi = 90 - latitude\n",
    "    phi1 = (90.0 - lat1)*degrees_to_radians\n",
    "    phi2 = (90.0 - lat2)*degrees_to_radians\n",
    "         \n",
    "    # theta = longitude\n",
    "    theta1 = long1*degrees_to_radians\n",
    "    theta2 = long2*degrees_to_radians\n",
    "          \n",
    "    # Compute spherical distance from spherical coordinates.\n",
    "    try:     \n",
    "        cos = (math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2) + \n",
    "               math.cos(phi1)*math.cos(phi2))\n",
    "        arc = math.acos( cos )\n",
    "    except: \n",
    "        print str(lat1)+\",\"+str(long1)+\",\"+str(lat2)+\",\"+str(long2)\n",
    "        print o_bid\n",
    "        print n_bid\n",
    "    \n",
    "    #multiply with radius of earth in kms to get the actual value\n",
    "    return arc*6371\n",
    "\n",
    "def getHourAttr(old, new):\n",
    "    if old[u'close'] == new[u'close'] and old[u'open'] == new[u'open']:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def getParkingAttr(old, new):\n",
    "    parking_keys = [u'garage', u'street', u'validated', u'lot', u'valet']\n",
    "    '''if np.isnan(old['attributes_Parking']) or math.isnan(new['attributes_Parking']):\n",
    "        return -1\n",
    "    '''\n",
    "    for key in parking_keys:\n",
    "        try:\n",
    "            if old['attributes_Parking'][key]!= new['attributes_Parking'][key]:\n",
    "                return -1\n",
    "        except KeyError, e:\n",
    "            '''print 'I got a KeyError - reason \"%s\"' % str(e)\n",
    "            print \"Old: \", old\n",
    "            print \"New: \", new\n",
    "            break'''\n",
    "            return -1\n",
    "    return 1\n",
    "\n",
    "def getCategoryAttr(old, new):\n",
    "    #print old, new\n",
    "    oldCategories = set(old.encode('utf8').split(','))\n",
    "    newCategories = set(new.encode('utf8').split(','))\n",
    "    L = len(oldCategories.intersection(newCategories))\n",
    "    return L\n",
    "    \n",
    "def getVector(old, new):\n",
    "    res = []\n",
    "    for attr in attrs:\n",
    "        if attr == 'distance':\n",
    "            res.append(find_distance(0, 0, old, new))\n",
    "            continue\n",
    "            \n",
    "        if pd.isnull(old[attr]) and pd.isnull(new[attr]):\n",
    "            res.append(1)\n",
    "            continue\n",
    "            \n",
    "        elif pd.isnull(old[attr]) or pd.isnull(new[attr]):\n",
    "            res.append(-1)\n",
    "            continue\n",
    "\n",
    "        if attr == u'attributes_Price Range':\n",
    "            if new[attr].astype(float) < old[attr].astype(float):\n",
    "                res.append(-10)\n",
    "            else:\n",
    "                res.append(0)\n",
    "            continue\n",
    "            \n",
    "        if 'hours_' in attr:\n",
    "            res.append(getHourAttr(old[attr], new[attr]))\n",
    "            continue\n",
    "            \n",
    "        if attr == u'categories':\n",
    "            res.append(getCategoryAttr(old[attr], new[attr]))\n",
    "            continue\n",
    "            \n",
    "        if attr == u'attributes_Parking':\n",
    "            res.append(getParkingAttr(old, new))\n",
    "            continue\n",
    "\n",
    "        elif old[attr] == new[attr]:\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(-1)\n",
    "    return res\n",
    "\n",
    "#Testing Out Vector Nonsense \n",
    "c = 0\n",
    "pd_business =  pd_lasvegas[pd_lasvegas['cluster'] == c]\n",
    "pd_old_business = pd_business[pd_business['new'] == False]\n",
    "pd_new_business = pd_business[pd_business['new'] == True]\n",
    "print getVector(pd_old_business.iloc[0], pd_new_business.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Conditional Mean For Each Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for :  60\n",
      "Calculating vector for cluster  0\n",
      "Time taken for cluster  0  is  584.216160059\n",
      "Completed calculating vector for cluster  0\n",
      "66123\n",
      "66123\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "''' Helper for Date in Pandas'''\n",
    "def todate(d):\n",
    "    return datetime.datetime.strptime(d, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "''' Calculate mean_after - mean_before : returns +1 if mean improves -1 if mean reduces'''\n",
    "def calcAverage(df):\n",
    "    #print \"Printing DF\", df\n",
    "    df_before = df[df['before'] == True]\n",
    "    df_after = df[df['before'] == False]\n",
    "    \n",
    "    #print \"before\", df_before\n",
    "    #print \"after\", df_after\n",
    "    \n",
    "    l1 = len(df_before['stars'])\n",
    "    l2 = len(df_after['stars'])\n",
    "\n",
    "    if l1 == 0 or l2 == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        a = sum(df_before['stars']) / (len(df_before['stars'])*1.0)\n",
    "        b = sum(df_after['stars']) / (len(df_after['stars'])*1.0)\n",
    "        if a - b > 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "def createTrainingData(c=0, date_range=60, sampleAll=True, maxsamples=0):\n",
    "    # Use cluster 0,1 for training\n",
    "    X, Y = [], []\n",
    "\n",
    "    diff = datetime.timedelta(days=date_range)\n",
    "    pd_business_cluster =  pd_lasvegas[pd_lasvegas['cluster'] == c]\n",
    "    pd_old_business = pd_business_cluster[pd_business_cluster['new'] == False]\n",
    "    #pd_old_business_Y = pd_business_cluster[[\"business_id\", \"review_date\", \"stars\"]] # This is to simplify Y calculation\n",
    "    pd_new_business = pd_business_cluster[pd_business_cluster['new'] == True]\n",
    "    gb_new_business = pd_new_business.groupby('business_id')\n",
    "    gb_old_business = pd_old_business.groupby('business_id')\n",
    "\n",
    "    \n",
    "    print \"Calculating vector for cluster \", c\n",
    "    start_time = time.time()\n",
    "    for new_business_id, new_business_details in gb_new_business:\n",
    "        start_date = todate(pd_new_business.iloc[0]['start_date'])\n",
    "        new_business = new_business_details.iloc[0]\n",
    "        \n",
    "        ''' Calculating Y for Current New Business '''\n",
    "        # Getting all old business reviews between start_date -diff to start_date + diff\n",
    "        pd_old_business_tempY = pd_old_business[pd_old_business.review_date.apply(todate) <= start_date + diff]\n",
    "        pd_old_business_tempY = pd_old_business_tempY[pd_old_business_tempY.review_date.apply(todate) >= start_date - diff]\n",
    "        \n",
    "        # Labelling All Reviews Before Start Date as True\n",
    "        pd_old_business_tempY['before'] = (pd_old_business_tempY['review_date'].apply(todate) < start_date)\n",
    "        \n",
    "        #print pd_old_business_tempY.groupby('business_id')\n",
    "        gb_old_business_tempY = pd_old_business_tempY.groupby(['business_id'])\n",
    "        temp_y = gb_old_business_tempY.apply(calcAverage).values.tolist()\n",
    "        \n",
    "        ''' Calculating X for Current New Business '''\n",
    "        temp_x = []\n",
    "        for old_business_id, old_business_details in gb_old_business_tempY:\n",
    "            old_business = old_business_details.iloc[0]\n",
    "            #print old_business\n",
    "            temp_x.append(getVector(old_business, new_business))\n",
    "            \n",
    "            \n",
    "        X.extend(temp_x)\n",
    "        Y.extend(temp_y)\n",
    "        \n",
    "        if sampleAll == False and len(X) > maxsamples:\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    print \"Time taken for cluster \", c, \" is \", end_time - start_time\n",
    "    print \"Completed calculating vector for cluster \", c\n",
    "    print len(X)\n",
    "    print len(Y)\n",
    "    return X, Y\n",
    "\n",
    "for i in [60]:\n",
    "    print \"Data for : \", i\n",
    "    X, Y = createTrainingData(c=0, date_range=i)\n",
    "    #pickle.dump(X, open('X_'+str(i)+'.pkl', 'wb'))\n",
    "    #pickle.dump(Y, open('Y_'+str(i)+'.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Algorithm: Logistic Regression/SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At cluster  60\n",
      "Regression Scores:  [ 0.66633903  0.66381853  0.66643981  0.66250756  0.65819722]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors, linear_model\n",
    "\n",
    "for i in [60]:\n",
    "    print \"At cluster \", i\n",
    "    #X = pickle.load(open('X_'+str(i)+'.pkl', 'rb'))\n",
    "    #Y = pickle.load(open('Y_'+str(i)+'.pkl', 'rb'))\n",
    "    X_np, Y_np = np.array(X), np.array(Y)\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "    scores = cross_validation.cross_val_score(logistic, X_np, Y_np, cv=5)\n",
    "    print \"Regression Scores: \", scores\n",
    "\n",
    "#sampling_mask_train =np.random.randint(len(X),size=10000)\n",
    "#sampling_mask_test =np.random.randint(len(X),size=2500)\n",
    "#X_train, Y_train = X_np[sampling_mask_train,:], Y_np[sampling_mask_train]\n",
    "#X_test, Y_test = X_np[sampling_mask_test,:], Y_np[sampling_mask_test]\n",
    "\n",
    "#clf = SVC(kernel='rbf')\n",
    "#print('SVM score: %f' % clf.fit(X_train, Y_train).score(X_test, Y_test))\n",
    "#scores = cross_validation.cross_val_score(clf, X_np, Y_np, cv=5)\n",
    "#print  \"SVM Scores: \" , scores\n",
    "\n",
    "#clf2 = SVC(kernel='linear')\n",
    "#print('Linear SVM score: %f' % clf2.fit(X_train, Y_train).score(X_test, Y_test))\n",
    "#clf3 = SVC(kernel='poly')\n",
    "#print('Poly Linear SVM score: %f' % clf3.fit(X_train, Y_train).score(X_test, Y_test))\n",
    "#clf4 = SVC(kernel='sigmoid')\n",
    "#print('Sigmoid Linear SVM score: %f' % clf4.fit(X_train, Y_train).score(X_test, Y_test))\n",
    "#clf = SVC(kernel='rbf')\n",
    "#print('SVM score: %f' % clf.fit(X_train, Y_train).score(X_test, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
